## Os ServiceMonitors
Um dos principais recursos que o Kube-Prometheus utiliza √© o ServiceMonitor. O ServiceMonitor √© um recurso do Prometheus Operator que permite que voc√™ configure o Prometheus para monitorar um servi√ßo. Para isso, voc√™ precisa criar um ServiceMonitor para cada servi√ßo que voc√™ deseja monitorar.

O ServiceMonitor define o conjunto de endpoints a serem monitorados pelo Prometheus e tamb√©m fornece informa√ß√µes adicionais, como o caminho e a porta de um endpoint, al√©m de permitir a defini√ß√£o de r√≥tulos personalizados. Ele pode ser usado para monitorar os endpoints de um aplicativo ou de um servi√ßo espec√≠fico em um cluster Kubernetes.

Voc√™ consegue criar algumas regras com o objetivo de filtrar quais ser√£o os targets que o Prometheus ir√° monitorar. Por exemplo, voc√™ pode criar uma regra para monitorar apenas os pods que est√£o com o label `app=nginx` ou ainda capturar as m√©tricas somente de endpoints que estejam com alguma label que voc√™ definiu.

O Kube-Prometheus j√° vem com v√°rios ServiceMonitors configurados, como por exemplo o ServiceMonitor do API Server, do Node Exporter, do Blackbox Exporter, etc.

```sh
kubectl get servicemonitors -n monitoring
```

```sh
NAME                      AGE
alertmanager              17m
blackbox-exporter         17m
coredns                   17m
grafana                   17m
kube-apiserver            17m
kube-controller-manager   17m
kube-scheduler            17m
kube-state-metrics        17m
kubelet                   17m
node-exporter             17m
prometheus-adapter        17m
prometheus-k8s            17m
prometheus-operator       17m
```
Para ver o conte√∫do de um ServiceMonitor, basta executar o seguinte comando:
```sh
kubectl get servicemonitor prometheus-k8s -n monitoring -o yaml
```
Nesse caso estamos pegando o ServiceMonitor do Prometheus, mas voc√™ pode pegar o ServiceMonitor de qualquer outro servi√ßo.
```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"monitoring.coreos.com/v1","kind":"ServiceMonitor","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"prometheus","app.kubernetes.io/instance":"k8s","app.kubernetes.io/name":"prometheus","app.kubernetes.io/part-of":"kube-prometheus","app.kubernetes.io/version":"2.41.0"},"name":"prometheus-k8s","namespace":"monitoring"},"spec":{"endpoints":[{"interval":"30s","port":"web"},{"interval":"30s","port":"reloader-web"}],"selector":{"matchLabels":{"app.kubernetes.io/component":"prometheus","app.kubernetes.io/instance":"k8s","app.kubernetes.io/name":"prometheus","app.kubernetes.io/part-of":"kube-prometheus"}}}}
  creationTimestamp: "2023-01-23T19:08:26Z"
  generation: 1
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: k8s
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 2.41.0
  name: prometheus-k8s
  namespace: monitoring
  resourceVersion: "4100"
  uid: 6042e08c-cf18-4622-9860-3ff43e696f7c
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
```
Eu vou dar uma limpada nessa sa√≠da para ficar mais f√°cil de entender:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  annotations:
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: k8s
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 2.41.0
  name: prometheus-k8s
  namespace: monitoring
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:s
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
```
Pronto, eu tirei algumas informa√ß√µes que n√£o s√£o importantes para a cria√ß√£o do ServiceMonitor, elas apenas trazer as informa√ß√µes do service monitor que foi criado e que pegamos a sa√≠da.

Com o arquivo limpo, podemos entender melhor o que est√° acontecendo.

- `apiVersion:` Vers√£o da API do Kubernetes que estamos utilizando.
- `kind:` Tipo de objeto que estamos criando.
- `metadata:` Informa√ß√µes sobre o objeto que estamos criando.
- `metadata.annotations: `Anota√ß√µes que podemos adicionar ao nosso objeto.
- `metadata.labels:` Labels que podemos adicionar ao nosso objeto.
- `metadata.name:` Nome do nosso objeto.
- `metadata.namespace:` Namespace onde o nosso objeto ser√° criado.
- `spec:`Especifica√ß√µes do nosso objeto.
- `spec.endpoints:` Endpoints que o nosso ServiceMonitor ir√° monitorar.
- `spec.endpoints.interval:` Intervalo de tempo que o Prometheus ir√° fazer a coleta de m√©tricas.
- `spec.endpoints.port:` Porta que o Prometheus ir√° utilizar para coletar as m√©tricas.
- `spec.selector:` Selector que o ServiceMonitor ir√° utilizar para encontrar os servi√ßos que ele ir√° monitorar.
Com isso, sabemos que o ServiceMonitor do Prometheus ir√° monitorar os servi√ßos que possuem as labels `app.kubernetes.io/component: prometheus`, `app.kubernetes.io/instance: k8s`,` app.kubernetes.io/name: prometheus` e `app.kubernetes.io/part-of: kube-prometheus`, e que ele ir√° monitorar as portas `web` e` reloader-web` com um intervalo de 30 segundos. √â f√°cil ou n√£o √©?

Ent√£o sempre que precisarmos criar um ServiceMonitor para monitorar algum servi√ßo, basta criarmos um arquivo YAML com as informa√ß√µes que precisamos e aplicarmos em nosso cluster.

### Vamos criar o nosso ServiceMonitor com o seguinte arquivo YAML:
```sh
apiVersion: monitoring.coreos.com/v1 # vers√£o da API
kind: ServiceMonitor # tipo de recurso, no caso, um ServiceMonitor do Prometheus Operator
metadata: # metadados do recurso
  name: nginx-servicemonitor # nome do recurso
  labels: # labels do recurso
    app: nginx # label que identifica o app
spec: # especifica√ß√£o do recurso
  selector: # seletor para identificar os pods que ser√£o monitorados
    matchLabels: # labels que identificam os pods que ser√£o monitorados
      app: nginx # label que identifica o app que ser√° monitorado
  endpoints: # endpoints que ser√£o monitorados
    - interval: 10s # intervalo de tempo entre as requisi√ß√µes
      path: /metrics # caminho para a requisi√ß√£o
      targetPort: 9113 # porta do target
```
### Agora vamos entender o que est√° acontecendo no nosso arquivo YAML.

- `apiVersion:` Vers√£o da API do Kubernetes que estamos utilizando.
- `kind:` Tipo de objeto que estamos criando, no nosso caso, um ServiceMonitor.
- `metadata:` Informa√ß√µes sobre o objeto que estamos criando.
- `metadata.name:` Nome do nosso objeto.
- `metadata.labels:` Labels que ser√£o utilizadas para identificar o nosso objeto.
- `spec:` Especifica√ß√µes do nosso objeto.
- `spec.selector:` Seletor que ser√° utilizado para identificar o nosso Service.
- `spec.selector.matchLabels:` Labels que ser√£o utilizadas para identificar o nosso Service, no nosso caso, o Service que tema - label` app: nginx.`
- `spec.endpoints:` Endpoints que ser√£o monitorados pelo Prometheus.
- `spec.endpoints.interval:` Intervalo de tempo que o Prometheus ir√° capturar as m√©tricas, no nosso caso, 15 segundos.
- `spec.endpoints.path:` Caminho que o Prometheus ir√° fazer a requisi√ß√£o para capturar as m√©tricas, no nosso caso, /metrics.
- `spec.endpoints.targetPort:` Porta que o Prometheus ir√° fazer a requisi√ß√£o para capturar as m√©tricas, no nosso caso, `9113.`

### Vamos criar o nosso ServiceMonitor com o seguinte comando:
```sh
kubectl apply -f nginx-service-monitor.yaml
```
Maravilha! Agora que j√° temos o nosso Nginx rodando e as m√©tricas sendo expostas, vamos verificar se o Prometheus est√° capturando as m√©tricas do Nginx e do Nginx Exporter.

Vamos fazer o port-forward do Prometheus para acessar o Prometheus localmente:
```sh
kubectl port-forward -n monitoring svc/prometheus-k8s 39090:9090
```
E agora vamos usar o curl para verificar se o Prometheus est√° capturando as m√©tricas do Nginx e do Nginx Exporter:
```sh
curl http://localhost:39090/api/v1/targets
```
Pronto, agora voc√™ j√° sabe como que faz para criar um Service no Kubernetes, expor as m√©tricas do Nginx e do Nginx Exporter e ainda criar um ServiceMonitor para o seu Service ficar monitorado pelo Prometheus. \o/

√â muito importante que voc√™ saiba que o Prometheus n√£o captura as m√©tricas automaticamente, ele precisa de um ServiceMonitor para capturar as m√©tricas.

### Os PodMonitors
E quando o nosso workload n√£o √© um Service? E quando o nosso workload √© um Pod? Como que faz para monitorar o Pod?
Tem situa√ß√µes que n√£o temos um service na frente de nossos pods, por exemplo, quando temos CronJobs, Jobs, DaemonSets, etc. Eu j√° vi situa√ß√µes onde o pessoal estavam utilizando o PodMonitor para monitorar pods n√£o HTTP, por exemplo, pods que exp√µem m√©tricas do RabbitMQ, do Redis, Kafka, etc.

### Criando um PodMonitor
Para criar um PodMonitor, quase n√£o teremos muitas mudan√ßas do que aprendemos para criar um ServiceMonitor. Vamos criar o nosso PodMonitor com o seguinte arquivo YAML chamado nginx-pod-monitor.yaml:

```sh
apiVersion: monitoring.coreos.com/v1 # vers√£o da API
kind: PodMonitor # tipo de recurso, no caso, um PodMonitor do Prometheus Operator
metadata: # metadados do recurso
  name: nginx-podmonitor # nome do recurso
  labels: # labels do recurso
    app: nginx # label que identifica o app
spec:
  namespaceSelector: # seletor de namespaces
    matchNames: # namespaces que ser√£o monitorados
      - default # namespace que ser√° monitorado
  selector: # seletor para identificar os pods que ser√£o monitorados
    matchLabels: # labels que identificam os pods que ser√£o monitorados
      app: nginx # label que identifica o app que ser√° monitorado
  podMetricsEndpoints: # endpoints que ser√£o monitorados
    - interval: 10s # intervalo de tempo entre as requisi√ß√µes
      path: /metrics # caminho para a requisi√ß√£o
      targetPort: 9113 # porta do target
```
Veja que usamos quase que as mesmas op√ß√µes do ServiceMonitor, a √∫nica diferen√ßa √© que usamos o podMetricsEndpoints para definir os endpoints que ser√£o monitorados.
Outra novidade para n√≥s √© o namespaceSelector, que √© utilizado para selecionar os namespaces que ser√£o monitorados. No nosso caso, estamos monitorando o namespace default, onde estar√° em execu√ß√£o o nosso Pod do Nginx.

Antes de deployar o nosso PodMonitor, vamos criar o nosso Pod do Nginx com o seguinte arquivo YAML chamado `nginx-pod.yaml:`

```sh
apiVersion: v1 # vers√£o da API
kind: Pod # tipo de recurso, no caso, um Pod
metadata: # metadados do recurso
  name: nginx-pod # nome do recurso
  labels: # labels do recurso
    app: nginx # label que identifica o app
spec: # especifica√ß√µes do recursos
  containers: # containers do template 
    - name: nginx-container # nome do container
      image: nginx # imagem do container do Nginx
      ports: # portas do container
        - containerPort: 80 # porta do container
          name: http # nome da porta
      volumeMounts: # volumes que ser√£o montados no container
        - name: nginx-config # nome do volume
          mountPath: /etc/nginx/conf.d/default.conf # caminho de montagem do volume
          subPath: nginx.conf # subpath do volume
    - name: nginx-exporter # nome do container que ser√° o exporter
      image: 'nginx/nginx-prometheus-exporter:0.11.0' # imagem do container do exporter
      args: # argumentos do container
        - '-nginx.scrape-uri=http://localhost/metrics' # argumento para definir a URI de scraping
      resources: # recursos do container
        limits: # limites de recursos
          memory: 128Mi # limite de mem√≥ria
          cpu: 0.3 # limite de CPU
      ports: # portas do container
        - containerPort: 9113 # porta do container que ser√° exposta
          name: metrics # nome da porta
  volumes: # volumes do template
    - configMap: # configmap do volume, n√≥s iremos criar esse volume atrav√©s de um configmap
        defaultMode: 420 # modo padr√£o do volume
        name: nginx-config # nome do configmap
      name: nginx-config # nome do volume
```
Pronto, com o nosso Pod criado, vamos criar o nosso PodMonitor utilizando o arquivo YAML chamado `nginx-pod-monitor.yaml`, que criamos anteriormente:
```sh
kubectl apply -f nginx-pod-monitor.yaml
```
Vamos verificar os PodMonitors que est√£o criados em nosso cluster:
```sh
kubectl get podmonitors
```
Caso voc√™ queira ver os PodMonitors em detalhes, basta executar o seguinte comando:
```sh
kubectl describe podmonitors nginx-podmonitor
```
E claro, voc√™ pode fazer o mesmo com o ServiceMonitor, basta executar o seguinte comando:
```sh
kubectl describe servicemonitors nginx-servicemonitor
```
Vamos ver a saida do describe para o nosso PodMonitor:
```sh
Name:         nginx-podmonitor
Namespace:    default
Labels:       app=nginx
Annotations:  <none>
API Version:  monitoring.coreos.com/v1
Kind:         PodMonitor
Metadata:
  Creation Timestamp:  2023-03-01T17:17:13Z
  Generation:          1
  Managed Fields:
    API Version:  monitoring.coreos.com/v1
    Fields Type:  FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .:
          f:kubectl.kubernetes.io/last-applied-configuration:
        f:labels:
          .:
          f:app:
      f:spec:
        .:
        f:namespaceSelector:
          .:
          f:matchNames:
        f:podMetricsEndpoints:
        f:selector:
    Manager:         kubectl-client-side-apply
    Operation:       Update
    Time:            2023-03-01T17:17:13Z
  Resource Version:  9473
  UID:               8c1bb91c-7285-4184-90e7-dcffcb143b92
Spec:
  Namespace Selector:
    Match Names:
      default
  Pod Metrics Endpoints:
    Interval:  10s
    Path:      /metrics
    Port:      9113
  Selector:
    Match Labels:
      App:  nginx
Events:     <none>
```
Como podemos ver, o nosso PodMonitor foi criado com sucesso. üòÑ

Agora vamos ver se ele est√° aparecendo como um target no Prometheus. Para isso, vamos acessar o Prometheus localmente atrav√©s do` kubectl port-forward:`
```sh
kubectl port-forward -n monitoring svc/prometheus-k8s 39090:9090
```
Pronto, corre l√° conferir o seu mais novo target e as m√©tricas que est√£o sendo coletadas. üòÑ

Uma coisa que vale a pena lembrar, √© que voc√™ pode acessar o container com o kubectl exec e verificar se o seu exporter est√° funcionando corretamente ou somente para conferir quais s√£o as m√©tricas que ele est√° expondo para o Prometheus. Para isso, basta executar o seguinte comando:
```sh
kubectl exec -it nginx-pod -c nginx-exporter -- bash
```
Agora vamos utilizar o curl para verificar se o nosso exporter est√° funcionando corretamente:
```sh
curl localhost:9113/metrics
```
Se tudo est√° funcionando corretamente, voc√™ deve ver uma sa√≠da parecida com a seguinte:
```sh
# HELP nginx_connections_accepted Accepted client connections
# TYPE nginx_connections_accepted counter
nginx_connections_accepted 1
# HELP nginx_connections_active Active client connections
# TYPE nginx_connections_active gauge
nginx_connections_active 1
# HELP nginx_connections_handled Handled client connections
# TYPE nginx_connections_handled counter
nginx_connections_handled 1
# HELP nginx_connections_reading Connections where NGINX is reading the request header
# TYPE nginx_connections_reading gauge
nginx_connections_reading 0
# HELP nginx_connections_waiting Idle client connections
# TYPE nginx_connections_waiting gauge
nginx_connections_waiting 0
# HELP nginx_connections_writing Connections where NGINX is writing the response back to the client
# TYPE nginx_connections_writing gauge
nginx_connections_writing 1
# HELP nginx_http_requests_total Total http requests
# TYPE nginx_http_requests_total counter
nginx_http_requests_total 61
# HELP nginx_up Status of the last metric scrape
# TYPE nginx_up gauge
nginx_up 1
# HELP nginxexporter_build_info Exporter build information
# TYPE nginxexporter_build_info gauge
nginxexporter_build_info{arch="linux/amd64",commit="e4a6810d4f0b776f7fde37fea1d84e4c7284b72a",date="2022-09-07T21:09:51Z",dirty="false",go="go1.19",version="0.11.0"} 1
```
Lembrando que voc√™ pode consultar todas essas m√©tricas l√° no seu Prometheus. üòÑ

### Bora mudar um pouco de assunto? Vamos falar sobre alertas!

Criando nosso primeiro alerta
Agora que j√° temos o nosso Kube-Prometheus instalado, vamos configurar o Prometheus para monitorar o nosso cluster `EKS`. Para isso, vamos utilizar o kubectl port-forward para acessar o Prometheus localmente. Para isso, basta executar o seguinte comando:
```sh
kubectl port-forward -n monitoring svc/prometheus-k8s 39090:9090
```
Se voc√™ quiser acessar o Alertmanager, basta executar o seguinte comando:
```sh
kubectl port-forward -n monitoring svc/alertmanager-main 39093:9093
```
Pronto, agora voc√™ j√° sabe como que faz para acessar o `Prometheus`, `AlertManager` e o `Grafana` localmente. üòÑ

Lembrando que voc√™ pode acessar o Prometheus e o AlertManager atrav√©s do seu navegador, basta acessar as seguintes URLs:

`Prometheus: http://localhost:39090`
`AlertManager: http://localhost:39093`
Simples assim!

Evidentemente, voc√™ pode expor esses servi√ßos para a internet ou para um VPC privado, mas isso √© assunto para voc√™ discutir com seu time.

Antes sair definindo um novo alerta, precisamos entender como faze-lo, uma vez que n√≥s n√£o temos mais o arquivo de alertas, igual t√≠nhamos quando instalamos o Prometheus em nosso servidor Linux.

Agora, precisamos entender que boa parte da configura√ß√£o do Prometheus est√° dentro de configmaps, que s√£o recursos do Kubernetes que armazenam dados em formato de chave e valor e s√£o muito utilizados para armazenar configura√ß√µes de aplica√ß√µes.

Para listar os `configmaps` do nosso cluster, basta executar o seguinte comando:
```sh
kubectl get configmaps -n monitoring
```
O resultado do comando acima dever√° ser parecido com o seguinte:
```sh
NAME                                                  DATA   AGE
adapter-config                                        1      7m20s
blackbox-exporter-configuration                       1      7m49s
grafana-dashboard-alertmanager-overview               1      7m46s
grafana-dashboard-apiserver                           1      7m46s
grafana-dashboard-cluster-total                       1      7m46s
grafana-dashboard-controller-manager                  1      7m45s
grafana-dashboard-grafana-overview                    1      7m44s
grafana-dashboard-k8s-resources-cluster               1      7m44s
grafana-dashboard-k8s-resources-namespace             1      7m44s
grafana-dashboard-k8s-resources-node                  1      7m43s
grafana-dashboard-k8s-resources-pod                   1      7m42s
grafana-dashboard-k8s-resources-workload              1      7m42s
grafana-dashboard-k8s-resources-workloads-namespace   1      7m41s
grafana-dashboard-kubelet                             1      7m41s
grafana-dashboard-namespace-by-pod                    1      7m41s
grafana-dashboard-namespace-by-workload               1      7m40s
grafana-dashboard-node-cluster-rsrc-use               1      7m40s
grafana-dashboard-node-rsrc-use                       1      7m39s
grafana-dashboard-nodes                               1      7m39s
grafana-dashboard-nodes-darwin                        1      7m39s
grafana-dashboard-persistentvolumesusage              1      7m38s
grafana-dashboard-pod-total                           1      7m38s
grafana-dashboard-prometheus                          1      7m37s
grafana-dashboard-prometheus-remote-write             1      7m37s
grafana-dashboard-proxy                               1      7m37s
grafana-dashboard-scheduler                           1      7m36s
grafana-dashboard-workload-total                      1      7m36s
grafana-dashboards                                    1      7m35s
kube-root-ca.crt                                      1      11m
prometheus-k8s-rulefiles-0                            8      7m10s
```
Como voc√™ pode ver, temos diversos configmaps que cont√©m configura√ß√µes do Prometheus, AlertManager e do Grafana. Vamos focar no configm`ap prometheus-k8s-rulefiles-0`, que √© o configmap que cont√©m os alertas do Prometheus.

Para visualizar o conte√∫do do configmap, basta executar o seguinte comando:
```sh
kubectl get configmap prometheus-k8s-rulefiles-0 -n monitoring -o yaml
```
Eu n√£o vou colar a sa√≠da inteira aqui porque ela √© enorme, mas vou colar um peda√ßo com um exemplo de alerta:
```yaml
- alert: KubeMemoryOvercommit
    annotations:
        description: Cluster has overcommitted memory resource requests for Pods by
        {{ $value | humanize }} bytes and cannot tolerate node failure.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubememoryovercommit
        summary: Cluster has overcommitted memory resource requests.
    expr: |
        sum(namespace_memory:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource="memory"}) - max(kube_node_status_allocatable{resource="memory"})) > 0
        and
        (sum(kube_node_status_allocatable{resource="memory"}) - max(kube_node_status_allocatable{resource="memory"})) > 0
    for: 10m
    labels:
        severity: warning
```
Como voc√™ pode ver, o alerta acima √© chamado de `KubeMemoryOvercommit` e ele √© disparado quando o cluster tem mais mem√≥ria alocada para os pods do que a mem√≥ria dispon√≠vel nos n√≥s. A sua defini√ß√£o √© a mesma que usamos quando criamos o arquivo de alertas no nosso servidor Linux.

### Criando um novo alerta
Muito bom, j√° sabemos que temos algumas regras j√° definidas, e que elas est√£o dentro de um configmap. Agora, vamos criar um novo alerta para monitorar o nosso Nginx.

Mas antes, precisamos entender o que √© um recurso chamado `PrometheusRule`.

### O que √© um PrometheusRule?
O PrometheusRule √© um recurso do Kubernetes que foi instalado no momento que realizamos a instala√ß√£o dos CRDs do kube-prometheus. O PrometheusRule permite que voc√™ defina alertas para o Prometheus. Ele √© muito parecido com o arquivo de alertas que criamos no nosso servidor Linux, por√©m nesse momento vamos fazer a mesma defini√ß√£o de alerta, mas usando o PrometheusRule.

### Criando um PrometheusRule
Vamos criar um arquivo chamado `nginx-prometheus-rule.yaml` e vamos colocar o seguinte conte√∫do:
```yaml
apiVersion: monitoring.coreos.com/v1 # Vers√£o da api do PrometheusRule
kind: PrometheusRule # Tipo do recurso
metadata: # Metadados do recurso (nome, namespace, labels)
  name: nginx-prometheus-rule
  namespace: monitoring
  labels: # Labels do recurso
    prometheus: k8s # Label que indica que o PrometheusRule ser√° utilizado pelo Prometheus do Kubernetes
    role: alert-rules # Label que indica que o PrometheusRule cont√©m regras de alerta
    app.kubernetes.io/name: kube-prometheus # Label que indica que o PrometheusRule faz parte do kube-prometheus
    app.kubernetes.io/part-of: kube-prometheus # Label que indica que o PrometheusRule faz parte do kube-prometheus
spec: # Especifica√ß√£o do recurso
  groups: # Lista de grupos de regras
  - name: nginx-prometheus-rule # Nome do grupo de regras
    rules: # Lista de regras
    - alert: NginxDown # Nome do alerta
      expr: up{job="nginx"} == 0 # Express√£o que ser√° utilizada para disparar o alerta
      for: 1m # Tempo que a express√£o deve ser verdadeira para que o alerta seja disparado
      labels: # Labels do alerta
        severity: critical # Label que indica a severidade do alerta
      annotations: # Anota√ß√µes do alerta
        summary: "Nginx is down" # T√≠tulo do alerta
        description: "Nginx is down for more than 1 minute. Pod name: {{ $labels.pod }}" # Descri√ß√£o do alerta
```
Agora, vamos criar o PrometheusRule no nosso cluster:
```sh
kubectl apply -f nginx-prometheus-rule.yaml
```
Agora, vamos verificar se o PrometheusRule foi criado com sucesso:
```sh
kubectl get prometheusrules -n monitoring
```
A sa√≠da deve ser parecida com essa:
```sh
NAME                              AGE
alertmanager-main-rules           92m
grafana-rules                     92m
kube-prometheus-rules             92m
kube-state-metrics-rules          92m
kubernetes-monitoring-rules       92m
nginx-prometheus-rule             20s
node-exporter-rules               91m
prometheus-k8s-prometheus-rules   91m
prometheus-operator-rules         91m
```
Agora n√≥s j√° temos um novo alerta configurado em nosso Prometheus. Lembrando que temos a integra√ß√£o com o AlertManager, ent√£o, quando o alerta for disparado, ele ser√° enviado para o` AlertManager` e o AlertManager vai enviar uma notifica√ß√£o, por exemplo, para o nosso `Slack`ou `e-mail`.

Voc√™ pode acessar o nosso alerta tanto no Prometheus quanto no AlertManager.

Vamos imaginar que voc√™ precisa criar um novo alerta para monitorar a quantidade de requisi√ß√µes simult√¢neas que o seu Nginx est√° recebendo. Para isso, voc√™ precisa criar uma nova regra no PrometheusRule. Podemos utilizar o mesmo arquivo` nginx-prometheus-rule.yaml` e adicionar a nova regra no final do arquivo:
```sh
apiVersion: monitoring.coreos.com/v1 # Vers√£o da api do PrometheusRule
kind: PrometheusRule # Tipo do recurso
metadata: # Metadados do recurso (nome, namespace, labels)
  name: nginx-prometheus-rule
  namespace: monitoring
  labels: # Labels do recurso
    prometheus: k8s # Label que indica que o PrometheusRule ser√° utilizado pelo Prometheus do Kubernetes
    role: alert-rules # Label que indica que o PrometheusRule cont√©m regras de alerta
    app.kubernetes.io/name: kube-prometheus # Label que indica que o PrometheusRule faz parte do kube-prometheus
    app.kubernetes.io/part-of: kube-prometheus # Label que indica que o PrometheusRule faz parte do kube-prometheus
spec: # Especifica√ß√£o do recurso
  groups: # Lista de grupos de regras
  - name: nginx-prometheus-rule # Nome do grupo de regras
    rules: # Lista de regras
    - alert: NginxDown # Nome do alerta
      expr: up{job="nginx"} == 0 # Express√£o que ser√° utilizada para disparar o alerta
      for: 1m # Tempo que a express√£o deve ser verdadeira para que o alerta seja disparado
      labels: # Labels do alerta
        severity: critical # Label que indica a severidade do alerta
      annotations: # Anota√ß√µes do alerta
        summary: "Nginx is down" # T√≠tulo do alerta
        description: "Nginx is down for more than 1 minute. Pod name: {{ $labels.pod }}" # Descri√ß√£o do alerta

    - alert: NginxHighRequestRate # Nome do alerta
        expr: rate(nginx_http_requests_total{job="nginx"}[5m]) > 10 # Express√£o que ser√° utilizada para disparar o alerta
        for: 1m # Tempo que a express√£o deve ser verdadeira para que o alerta seja disparado
        labels: # Labels do alerta
            severity: warning # Label que indica a severidade do alerta
        annotations: # Anota√ß√µes do alerta
            summary: "Nginx is receiving high request rate" # T√≠tulo do alerta
            description: "Nginx is receiving high request rate for more than 1 minute. Pod name: {{ $labels.pod }}" # Descri√ß√£o do alerta
```
Pronto, adicionamos uma nova defini√ß√£o de alerta em nosso PrometheusRule. Agora vamos atualizar o nosso PrometheusRule:
```sh
kubectl apply -f nginx-prometheus-rule.yaml
```
Agora, vamos verificar se o PrometheusRule foi atualizado com sucesso:
```sh
kubectl get prometheusrules -n monitoring nginx-prometheus-rule -o yaml
```
A sa√≠da deve ser parecida com essa:
```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"monitoring.coreos.com/v1","kind":"PrometheusRule","metadata":{"annotations":{},"labels":{"app.kubernetes.io/name":"kube-prometheus","app.kubernetes.io/part-of":"kube-prometheus","prometheus":"k8s","role":"alert-rules"},"name":"nginx-prometheus-rule","namespace":"monitoring"},"spec":{"groups":[{"name":"nginx-prometheus-rule","rules":[{"alert":"NginxDown","annotations":{"description":"Nginx is down for more than 1 minute. Pod name: {{ $labels.pod }}","summary":"Nginx is down"},"expr":"up{job=\"nginx\"} == 0","for":"1m","labels":{"severity":"critical"}},{"alert":"NginxHighRequestRate","annotations":{"description":"Nginx is receiving high request rate for more than 1 minute. Pod name: {{ $labels.pod }}","summary":"Nginx is receiving high request rate"},"expr":"rate(nginx_http_requests_total{job=\"nginx\"}[5m]) \u003e 10","for":"1m","labels":{"severity":"warning"}}]}]}}
  creationTimestamp: "2023-03-01T14:14:00Z"
  generation: 2
  labels:
    app.kubernetes.io/name: kube-prometheus
    app.kubernetes.io/part-of: kube-prometheus
    prometheus: k8s
    role: alert-rules
  name: nginx-prometheus-rule
  namespace: monitoring
  resourceVersion: "24923"
  uid: c0a6914d-9a54-4083-bdf8-ebfb5c19077d
spec:
  groups:
  - name: nginx-prometheus-rule
    rules:
    - alert: NginxDown
      annotations:
        description: 'Nginx is down for more than 1 minute. Pod name: {{ $labels.pod
          }}'
        summary: Nginx is down
      expr: up{job="nginx"} == 0
      for: 1m
      labels:
        severity: critical
    - alert: NginxHighRequestRate
      annotations:
        description: 'Nginx is receiving high request rate for more than 1 minute.
          Pod name: {{ $labels.pod }}'
        summary: Nginx is receiving high request rate
      expr: rate(nginx_http_requests_total{job="nginx"}[5m]) > 10
      for: 1m
      labels:
        severity: warning
```
Pronto, o alerta foi criado com sucesso e voc√™ pode conferir no Prometheus ou no AlertManager.

Com o novo alerta, caso o Nginx esteja recebendo mais de 10 requisi√ß√µes por minuto, o alerta ser√° disparado e voc√™ receber√° uma notifica√ß√£o no Slack ou e-mail, claro, dependendo da configura√ß√£o que voc√™ fez no AlertManager.

Acho que j√° podemos chamar o dia de hoje de sucesso absoluto, pois entendemos como funciona para criar um novo target para o Prometheus, bem como criar um novo alerta para o AlertManager/Prometheus.

Agora voc√™ precisa dar asas para a sua imagina√ß√£o e sair criando tudo que √© exemplo de de alerta que voc√™ bem entender, e claro, coloque mais servi√ßos no seu cluster Kubernetes para que voc√™ possa monitorar tudo que √© poss√≠vel atrav√©s do ServiceMonitor e PrometheusRule do Prometheus Operator, e claro, n√£o esque√ßa de compartilhar com a gente o que voc√™ criou.