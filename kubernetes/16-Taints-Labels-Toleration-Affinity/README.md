## O que vamos ver e aprender ?

Hoje √© dia de falar sobre `Taints`, `Tolerations`, `Affinity` e `Antiaffinity`. Vamos entender como eles podem nos ajudar no dia-a-dia na administra√ß√£o de um cluster `Kubernetes`.

Com eles podemos isolar `workloads`, garantir que Pods sejam agendados em Nodes espec√≠ficos e at√© mesmo evitar que Pods sejam agendados em determinados Nodes do cluster.

Bora l√°, pois o dia ser√° intenso de coisas novas e com certeza voc√™ vai aprender muito! Bora?

## O Nosso cluster de exemplo
Para que possamos ter alguns exemplos mais divertido, vamos imaginar que temos um empresa chamada Guilda, e que essa empresa tem o seu cluster `Kubernetes` de produ√ß√£o composto por 08 nodes, sendo 4 control planes e 4 workers. Ele est√° dividido em duas regi√µes, S√£o Paulo e Salvador, chamadas de guilda-br-sp e guilda-br-ssa respectivamente. E cada regi√£o tem dois datacenters, guilda-sp-1 e guilda-sp-2 em S√£o Paulo e guilda-br-ssa-1 e guilda-br-ssa-2 em Salvador.

```sh
kubectl get nodes
```

```sh
NAME                     STATUS   ROLES           AGE     VERSION
guilda-control-plane1   Ready    control-plane   65d     v1.27.3
guilda-control-plane2   Ready    control-plane   65d     v1.27.3
guilda-control-plane3   Ready    control-plane   65d     v1.27.3
guilda-control-plane4   Ready    control-plane   65d     v1.27.3
guilda-worker1          Ready    <none>          65d     v1.27.3
guilda-worker2          Ready    <none>          65d     v1.27.3
guilda-worker3          Ready    <none>          65d     v1.27.3
guilda-worker4          Ready    <none>          65d     v1.27.3
```
A nossa miss√£o √© criar as `Labels` e `Taints` necess√°rias para que nosso cluster fique organizado, seguro e com alta disponibilidade. E com isso, com alguns ajustes em nossos deployments, garantir que nossos Pods sejam agendados nos Nodes corretos e distribu√≠dos entre os datacenters corretamente.

A distribui√ß√£o dos nossos nodes nas regi√µes e datacenters √© a seguinte:

- guilda-br-sp

  - guilda-br-sp-1
    - guilda-control-plane1
    - guilda-worker3
  - guilda-br-sp-2
    - guilda-control-plane4
    - guilda-worker1
- guilda-br-ssa
  - guilda-br-ssa-1
    - guilda-control-plane2
    - guilda-worker2
  - guilda-br-ssa-2
    - guilda-control-plane3
    - guilda-worker4
  
A primeira coisa que precisamos fazer √© criar as `Labels` em nossos `Nodes`. Para isso, vamos utilizar o comando `kubectl label nodes` e vamos adicionar as labels `region` e `datacenter` em cada um dos nossos `Nodes`.

```sh
kubectl label nodes guilda-control-plane1 region=guilda-br-sp datacenter=guilda-br-sp-1
kubectl label nodes guilda-control-plane2 region=guilda-br-ssa datacenter=guilda-br-ssa-1
kubectl label nodes guilda-control-plane3 region=guilda-br-ssa datacenter=guilda-br-ssa-2
kubectl label nodes guilda-control-plane4 region=guilda-br-sp datacenter=guilda-br-sp-2
kubectl label nodes guilda-worker1 region=guilda-br-sp datacenter=guilda-br-sp-2
kubectl label nodes guilda-worker2 region=guilda-br-ssa datacenter=guilda-br-ssa-1
kubectl label nodes guilda-worker3 region=guilda-br-sp datacenter=guilda-br-sp-1
kubectl label nodes guilda-worker4 region=guilda-br-ssa datacenter=guilda-br-ssa-2
```
Com o comando acima estamos utilizando o `kubectl label nodes` para adicionar as `labels` `region` e `datacenter` em cada um dos nossos `Nodes`.
 Agora, se executarmos o comando veremos algo como:

 ```sh
 kubectl get nodes guilda-control-plane1 --show-labels
 ```

```sh
NAME                     STATUS   ROLES           AGE     VERSION   LABELS
guilda-control-plane1   Ready    control-plane   65d     v1.27.3    beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,datacenter=guilda-br-sp-1kubernetes.io/arch=amd64,kubernetes.io/hostname=guilda-control-plane1,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=region=guilda-br-sp
```
Pronto, as nossas` labels` est√£o criadas, com isso j√° conseguimos ter um pouco mais de organiza√ß√£o em nosso `cluster`.

Mas ainda n√£o acabou o nosso trabalho, cada uma das regi√µes possui um node com um `hardware` especial, que √© uma `GPU`. Vamos criar uma label para identificar esses `nodes`, mas por enquanto √© somente para identificar, n√£o vamos fazer nada com eles ainda.
```sh
kubectl label nodes guilda-worker1 gpu=true
```
```sh
kubectl label nodes guilda-worker4 gpu=true
```
Pronto, por enquanto isso resolve, mas com certeza precisaremos adicionar mais labels em nossos nodes no futuro, mas por enquanto isso j√° resolve o nosso problema.

Caso eu queira remover alguma Label, basta utilizar o comando `kubectl label nodes guilda-control-plane1 region-` e a label ser√° removida.

Agora vamos entender como funcionam as `Taints`.

## O que s√£o Taints?
Taints s√£o "manchas" ou "marca√ß√µes" aplicadas aos Nodes que os marcam para evitar que certos Pods sejam agendados neles. Essa √© uma forma bastante comum de isolar workloads em um cluster `Kubernetes`, por exemplo em momentos de manuten√ß√£o ou quando voc√™ tem Nodes com recursos especiais, como GPUs.

Os Taints s√£o aplicados nos Nodes e podem ter um efeito de `NoSchedule`, `PreferNoSchedule` ou `NoExecute`. O efeito `NoSchedule` faz com que o `Kubernetes` n√£o agende Pods nesse Node a menos que eles tenham uma Toleration correspondente. O efeito Prefer`NoSchedule` faz com que o `Kubernetes` tente n√£o agendar, mas n√£o √© uma garantia. E o efeito `NoExecute` faz com que os Pods existentes sejam removidos se n√£o tiverem uma Toleration correspondente.

Agora vamos entender isso na pr√°tica!

Em nosso primeiro exemplo vamos conhecer a `Taint` `NoSchedule`. Para que voc√™ possa configurar um `Taint` em um Node, voc√™ utiliza o comando kubectl `taint`. Por exemplo:
```sh
kubectl taint nodes guilda-worker1 key=value:NoSchedule
```
```sh
kubectl taint nodes guilda-worker1 key=value:NoSchedule
```
No comando acima, estamos aplicando um `Taint` no Node guilda-worker com a chave `key` e o valor `value` e com o efeito `NoSchedule`. Isso significa que o `Kubernetes` n√£o ir√° agendar nenhum Pod nesse Node a menos que ele tenha uma Toleration correspondente, que veremos mais adiante.

Nesse exemplo estamos utilizando a chave `key` e o valor `value`, mas voc√™ pode utilizar qualquer chave e valor que desejar. Por exemplo, voc√™ pode utilizar `environment=production` para marcar um Node como sendo de produ√ß√£o, ou gpu=true para marcar um Node com uma GPU.

Voc√™ ir√° entender melhor o porqu√™ de utilizar Taints e o porqu√™ de utilizar chaves e valores espec√≠ficos quando falarmos sobre Tolerations.

Para visualizar os Taints aplicados em um Node, voc√™ pode utilizar o comando kubectl describe node guilda-worker1. Voc√™ ver√° algo como:
```sh
Taints:             key=value:`NoSchedule`
```
Est√° l√° conforme esperado! Agora o que precisamos fazer √© testar!
O nosso cluster ainda n√£o est√° com nenhuma aplica√ß√£o em execu√ß√£o, somente os Pods do pr√≥prio `Kubernetes`, ent√£o vamos criar alguns para testar. üòÉ

Para esse teste, vamos criar um Deployment com 10 r√©plicas do Nginx, e vamos ver o que acontece.
```sh
kubectl create deployment nginx --image=nginx --replicas=10
```
Agora vamos verificar se os Pods foram criados e se est√£o em execu√ß√£o.
```sh
kubectl get pods -o wide
```
A sa√≠da ser√° algo como:

```sh
NAME                     READY   STATUS    RESTARTS   AGE   IP           NODE              NOMINATED NODE   READINESS GATES
nginx-77b4fdf86c-4rwb9   1/1     Running   0          12s   10.244.4.3   guilda-worker3   <none>           <none>
nginx-77b4fdf86c-chpgb   1/1     Running   0          12s   10.244.6.2   guilda-worker2   <none>           <none>
nginx-77b4fdf86c-dplq7   1/1     Running   0          12s   10.244.5.3   guilda-worker4   <none>           <none>
nginx-77b4fdf86c-l5vwq   1/1     Running   0          12s   10.244.6.4   guilda-worker2   <none>           <none>
nginx-77b4fdf86c-nwwvn   1/1     Running   0          12s   10.244.5.2   guilda-worker4   <none>           <none>
nginx-77b4fdf86c-qz9t4   1/1     Running   0          12s   10.244.5.4   guilda-worker4   <none>           <none>
nginx-77b4fdf86c-r4lt6   1/1     Running   0          12s   10.244.6.5   guilda-worker2   <none>           <none>
nginx-77b4fdf86c-rmqnm   1/1     Running   0          12s   10.244.4.4   guilda-worker3   <none>           <none>
nginx-77b4fdf86c-rsgbg   1/1     Running   0          12s   10.244.4.2   guilda-worker3   <none>           <none>
nginx-77b4fdf86c-wnxg7   1/1     Running   0          12s   10.244.6.3   guilda-worker2   <none>           <none>
```
Perceba que n√£o temos nenhum Pod em execu√ß√£o no Node `guilda-worker1`, que √© o Node que aplicamos o `Taint`. Isso acontece porque o `Kubernetes` n√£o ir√° agendar nenhum Pod nesse Node a menos que ele tenha uma Toleration correspondente, que veremos mais adiante.

Agora vamos remover o `Taint` do Node `guilda-worker1` e ver o que acontece.
```sh
kubectl taint nodes guilda-worker1 key=value:NoSchedule-
```
Os Pods n√£o ser√£o movidos automaticamente para o Node `guilda-worker1`, mas podemos usar o comando kubectl rollout restart deployment nginx para reiniciar o Deployment e o `Kubernetes` redistribuir√° os Pods entre os Nodes dispon√≠veis.

```sh
kubectl rollout restart deployment nginx
```
Agora vamos verificar se os Pods foram criados e se est√£o em execu√ß√£o.
```sh
kubectl get pods -o wide
```
A sa√≠da ser√° algo como:
```sh
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE              NOMINATED NODE   READINESS GATES
nginx-7c58f9889c-6qcpl   1/1     Running   0          28s   10.244.4.10   guilda-worker3   <none>           <none>
nginx-7c58f9889c-lj7p5   1/1     Running   0          29s   10.244.3.3    guilda-worker1   <none>           <none>
nginx-7c58f9889c-mdrj7   1/1     Running   0          29s   10.244.4.9    guilda-worker3   <none>           <none>
nginx-7c58f9889c-nr7h9   1/1     Running   0          29s   10.244.6.9    guilda-worker2   <none>           <none>
nginx-7c58f9889c-pqrb9   1/1     Running   0          26s   10.244.3.4    guilda-worker1   <none>           <none>
nginx-7c58f9889c-pzx7n   1/1     Running   0          29s   10.244.5.8    guilda-worker4   <none>           <none>
nginx-7c58f9889c-qn9hh   1/1     Running   0          28s   10.244.5.9    guilda-worker4   <none>           <none>
nginx-7c58f9889c-wmm2n   1/1     Running   0          26s   10.244.6.11   guilda-worker2   <none>           <none>
nginx-7c58f9889c-znrjt   1/1     Running   0          29s   10.244.3.2    guilda-worker1   <none>           <none>
nginx-7c58f9889c-zp9g9   1/1     Running   0          28s   10.244.6.10   guilda-worker2   <none>           <none>
```
Pronto, ele redistribuiu os Pods entre os Nodes dispon√≠veis, e voltou a executar Pods no Node `guilda-worker1`, afinal, n√≥s removemos o `Taint` dele.

Agora vamos testar o efeito `NoExecute`. Para isso, vamos aplicar um `Taint` no Node `guilda-worker1` com o efeito `NoExecute`.
```sh
kubectl taint nodes guilda-worker1 key=value:NoExecute
```
Diferente do efeito `NoSchedule`, o efeito `NoExecute` faz com que os Pods existentes sejam removidos se n√£o tiverem uma Toleration correspondente.

Vamos ver o que aconteceu com os nossos Pods.
```sh
NAME                     READY   STATUS    RESTARTS   AGE     IP            NODE              NOMINATED NODE   READINESS GATES
nginx-7c58f9889c-6qcpl   1/1     Running   0          2m29s   10.244.4.10   guilda-worker3   <none>           <none>
nginx-7c58f9889c-gm6tb   1/1     Running   0          5s      10.244.4.11   guilda-worker3   <none>           <none>
nginx-7c58f9889c-lnhmf   1/1     Running   0          5s      10.244.5.10   guilda-worker4   <none>           <none>
nginx-7c58f9889c-mdrj7   1/1     Running   0          2m30s   10.244.4.9    guilda-worker3   <none>           <none>
nginx-7c58f9889c-mz78w   1/1     Running   0          5s      10.244.6.12   guilda-worker2   <none>           <none>
nginx-7c58f9889c-nr7h9   1/1     Running   0          2m30s   10.244.6.9    guilda-worker2   <none>           <none>
nginx-7c58f9889c-pzx7n   1/1     Running   0          2m30s   10.244.5.8    guilda-worker4   <none>           <none>
nginx-7c58f9889c-qn9hh   1/1     Running   0          2m29s   10.244.5.9    guilda-worker4   <none>           <none>
nginx-7c58f9889c-wmm2n   1/1     Running   0          2m27s   10.244.6.11   guilda-worker2   <none>           <none>
nginx-7c58f9889c-zp9g9   1/1     Running   0          2m29s   10.244.6.10   guilda-worker2   <none>           <none>
```
Funcionou! Os Pods que estavam executando no Node `guilda-worker1` foram removidos e agendados em outros Nodes.

Nesse caso, o `Kubernetes` n√£o ir√° agendar nenhum Pod nesse Node a menos que ele tenha uma Toleration para o `Taint` que aplicamos.

Isso √© interessante em momentos que voc√™ precisa realizar manuten√ß√£o em um Node, garantindo que n√£o teremos nenhum Pod executando nele e que nenhum Pod ser√° agendado nesse Node.

Agora vamos remover o `Taint` do Node `guilda-worker1` e ver o que acontece.
```sh
kubectl taint nodes guilda-worker1 key=value:NoExecute-
```
Mais uma vez vale lembrar, o `Kubernetes` n√£o ir√° mover os Pods automaticamente para o `Node` `guilda-worker1`, mas podemos usar o comando` kubectl rollout restart deployment nginx` para reiniciar o Deployment e o `Kubernetes` redistribuir√° os Pods entre os Nodes dispon√≠veis.
```sh
kubectl rollout restart deployment nginx
```
Simples como voar!

Agora vamos entender o efeito `PreferNoSchedule`. Para isso, vamos aplicar um `Taint` no `Node` `guilda-worker1` com o efeito `PreferNoSchedule`.
```sh
kubectl taint nodes guilda-worker1 key=value:PreferNoSchedule
```
Diferente do efeito `NoSchedule`, o efeito `PreferNoSchedule` faz com que o `Kubernetes` tente n√£o agendar, mas n√£o √© uma garantia.

Ele tentar√° agendar os Pods em outros Nodes, mas se n√£o for poss√≠vel, ele ir√° agendar no Node que tem o `Taint`.

Os nossos Pods est√£o distribuidos da seguinte forma:
```sh
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE              NOMINATED NODE   READINESS GATES
nginx-67668985bc-6h2ml   1/1     Running   0          9s    10.244.3.5    guilda-worker1   <none>           <none>
nginx-67668985bc-dbnxr   1/1     Running   0          9s    10.244.5.11   guilda-worker4   <none>           <none>
nginx-67668985bc-hxkt8   1/1     Running   0          9s    10.244.3.6    guilda-worker1   <none>           <none>
nginx-67668985bc-ldwck   1/1     Running   0          9s    10.244.6.13   guilda-worker2   <none>           <none>
nginx-67668985bc-nvcd8   1/1     Running   0          7s    10.244.3.7    guilda-worker1   <none>           <none>
nginx-67668985bc-pwz4d   1/1     Running   0          9s    10.244.4.12   guilda-worker3   <none>           <none>
nginx-67668985bc-v2s2b   1/1     Running   0          7s    10.244.4.13   guilda-worker3   <none>           <none>
nginx-67668985bc-xdqjw   1/1     Running   0          7s    10.244.5.13   guilda-worker4   <none>           <none>
nginx-67668985bc-xkdt8   1/1     Running   0          7s    10.244.5.12   guilda-worker4   <none>           <none>
nginx-67668985bc-zdtsq   1/1     Running   0          7s    10.244.6.14   guilda-worker2   <none>           <none>
```
Temos Pods em execu√ß√£o no `Node` `guilda-worker1`, que √© o Node que aplicamos o `Taint`, pois esses `Pods` j√° estavam em execu√ß√£o antes de aplicarmos o `Taint`.

Agora vamos aumentar o n√∫mero de r√©plicas do nosso Deployment para 20 e ver o que acontece.
```sh
kubectl scale deployment nginx --replicas=20
```
Agora vamos verificar se os Pods foram criados e se est√£o em execu√ß√£o.
```sh
kubectl get pods -o wide
```
A sa√≠da ser√° algo como:
```sh
NAME                     READY   STATUS    RESTARTS   AGE     IP            NODE              NOMINATED NODE   READINESS GATES
nginx-67668985bc-6h2ml   1/1     Running   0          2m24s   10.244.3.5    guilda-worker1   <none>           <none>
nginx-67668985bc-9298b   1/1     Running   0          22s     10.244.5.17   guilda-worker4   <none>           <none>
nginx-67668985bc-c8nck   1/1     Running   0          22s     10.244.4.17   guilda-worker3   <none>           <none>
nginx-67668985bc-dbnxr   1/1     Running   0          2m24s   10.244.5.11   guilda-worker4   <none>           <none>
nginx-67668985bc-fds62   1/1     Running   0          22s     10.244.6.18   guilda-worker2   <none>           <none>
nginx-67668985bc-gtmq8   1/1     Running   0          22s     10.244.4.19   guilda-worker3   <none>           <none>
nginx-67668985bc-hxkt8   1/1     Running   0          2m24s   10.244.3.6    guilda-worker1   <none>           <none>
nginx-67668985bc-kbtqc   1/1     Running   0          22s     10.244.4.20   guilda-worker3   <none>           <none>
nginx-67668985bc-ldwck   1/1     Running   0          2m24s   10.244.6.13   guilda-worker2   <none>           <none>
nginx-67668985bc-mtsxv   1/1     Running   0          22s     10.244.6.19   guilda-worker2   <none>           <none>
nginx-67668985bc-nvcd8   1/1     Running   0          2m22s   10.244.3.7    guilda-worker1    <none>           <none>
nginx-67668985bc-pwz4d   1/1     Running   0          2m24s   10.244.4.12   guilda-worker3   <none>           <none>
nginx-67668985bc-snvnt   1/1     Running   0          22s     10.244.5.16   guilda-worker4   <none>           <none>
nginx-67668985bc-txgd4   1/1     Running   0          22s     10.244.4.18   guilda-worker3   <none>           <none>
nginx-67668985bc-v2s2b   1/1     Running   0          2m22s   10.244.4.13   guilda-worker3   <none>           <none>
nginx-67668985bc-w9hmj   1/1     Running   0          22s     10.244.6.20   guilda-worker2   <none>           <none>
nginx-67668985bc-xdqjw   1/1     Running   0          2m22s   10.244.5.13   guilda-worker4   <none>           <none>
nginx-67668985bc-xkdt8   1/1     Running   0          2m22s   10.244.5.12   guilda-worker4   <none>           <none>
nginx-67668985bc-zdtsq   1/1     Running   0          2m22s   10.244.6.14   guilda-worker2   <none>           <none>
nginx-67668985bc-zfglb   1/1     Running   0          22s     10.244.6.21   guilda-worker2   <none>           <none>
```
O que vemos na sa√≠da do comando √© que o `Kube-Scheduler `agendou os `Pods` em outros Nodes, mantendo somente os Pods que j√° estavam em execu√ß√£o no Node `guilda-worker1.`

O `Kube-scheduler` somente ir√° agendar novos pods no Node `guilda-worker1` se n√£o houver nenhum outro Node dispon√≠vel. Simples demais, n√£o?!?


## O que s√£o Tolerations?
Agora que entendemos como os Taints funcionam e como eles influenciam o agendamento de Pods nos Nodes, vamos mergulhar no mundo das Tolerations. As Tolerations s√£o como o "ant√≠doto" para os Taints. Elas permitem que um Pod seja agendado em um Node que possui um Taint espec√≠fico. Em outras palavras, elas "toleram" as Taints.

Vamos voltar ao nosso cluster da Strigus para entender melhor como isso funciona.

Imagine que temos um workload cr√≠tico que precisa ser executado em um Node com GPU. J√° marcamos nossos Nodes com GPU com a label `gpu=true`, e agora vamos usar Tolerations para garantir que nosso Pod possa ser agendado nesses Nodes. Isso n√£o faz com que o Pod seja agendado nesses Nodes, mas permite que ele seja agendado nesses Nodes. Entendeu a diferen√ßa?

Primeiro, vamos criar um Taint no Node guilda-worker1, que possui uma GPU.

kubectl taint nodes guilda-worker1 `gpu=true:NoSchedule`
Com esse Taint, estamos dizendo que nenhum Pod ser√° agendado nesse Node, a menos que ele tenha uma Toleration espec√≠fica para a Taint `gpu=true`.

Vamos criar um Deployment com 5 r√©plicas do Nginx e ver o que acontece.
```sh
kubectl create deployment nginx --image=nginx --replicas=5
```
Agora vamos verificar se os Pods foram criados e se est√£o em execu√ß√£o.
```sh
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE              NOMINATED NODE   READINESS GATES
nginx-77b4fdf86c-274jk   1/1     Running   0          5s    10.244.6.31   guilda-worker2   <none>           <none>
nginx-77b4fdf86c-97r8d   1/1     Running   0          5s    10.244.5.25   guilda-worker4   <none>           <none>
nginx-77b4fdf86c-cm96h   1/1     Running   0          5s    10.244.6.30   guilda-worker2   <none>           <none>
nginx-77b4fdf86c-rhdmh   1/1     Running   0          5s    10.244.4.29   guilda-worker3   <none>           <none>
nginx-77b4fdf86c-ttqzg   1/1     Running   0          5s    10.244.4.30   guilda-worker3   <none>           <none>
```
Como esperado, nenhum Pod foi agendado no Node guilda-worker1, que √© o Node que aplicamos o Taint.

Agora, vamos modificar o nosso Deployment do Nginx para que ele tenha uma Toleration para a Taint `gpu=true`.

Para ficar mais f√°cil, vamos criar um manifesto para o nosso Deployment utilizando o comando `kubectl create deployment nginx --image=nginx --replicas=5 --dry-run=client -o yaml > gpu-deployment.yaml`.

Agora vamos editar o arquivo gpu-deployment.yaml e adicionar a Toleration para a Taint gpu=true.
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx
  name: nginx
spec:
  replicas: 5
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx
        name: nginx
      tolerations:
      - key: gpu
        operator: Equal
        value: "true"
        effect: NoSchedule
```
Vamos entender o que adicionamos no arquivo.
```yaml
      tolerations:
      - key: gpu
        operator: Equal
        value: "true"
        effect: NoSchedule
```
Onde:

`key` √© a chave do Taint que queremos tolerar.
`operator` √© o operador que queremos utilizar. Nesse caso, estamos utilizando o operador Equal, que significa que o valor do Taint precisa ser igual ao valor da Toleration.
`value` √© o valor do Taint que queremos tolerar.
`effect` √© o efeito do Taint que queremos tolerar. Nesse caso, estamos utilizando o efeito `NoSchedule`, que significa que o Kubernetes n√£o ir√° agendar nenhum Pod nesse Node a menos que ele tenha uma Toleration correspondente.
Vamos aplicar esse Deployment e ver o que acontece.
```sh
kubectl apply -f gpu-deployment.yaml
```
Se verificarmos os Pods agora, veremos que o nosso Pod `gpu-pod` est√° rodando no Node `guilda-worker1`.
```sh
kubectl get pods -o wide
```
A sa√≠da mostrar√° algo como:
```sh
NAME                    READY   STATUS    RESTARTS   AGE   IP            NODE              NOMINATED NODE   READINESS GATES
nginx-7b68fffb4-czrpt   1/1     Running   0          11s   10.244.5.24   guilda-worker4   <none>           <none>
nginx-7b68fffb4-d577x   1/1     Running   0          11s   10.244.4.28   guilda-worker3   <none>           <none>
nginx-7b68fffb4-g2kxr   1/1     Running   0          11s   10.244.3.10   guilda-worker1    <none>           <none>
nginx-7b68fffb4-m5kln   1/1     Running   0          11s   10.244.6.29   guilda-worker2   <none>           <none>
nginx-7b68fffb4-n6kck   1/1     Running   0          11s   10.244.3.11   guilda-worker1    <none>           <none>
```
Isso demonstra o poder das Tolerations em combina√ß√£o com os Taints. Podemos controlar com precis√£o onde nossos Pods s√£o agendados, garantindo que workloads cr√≠ticos tenham os recursos que necessitam.

Para remover o Taint do Node` guilda-worker1`, basta usar o comando kubectl taint nodes `guilda-worker1 gpu=true:NoSchedule-`.

Mas lembrando mais uma vez, as Tolerations n√£o fazem com que o Pod seja agendado nesses Nodes, mas permite que ele seja agendado nesses Nodes.

Ent√£o, caso voc√™ queira garantir que determinado Pod seja executado em determinado Node, voc√™ precisa utilizar o conceito de Affinity, que veremos agora.

## O que s√£o Affinity e Antiaffinity?
Affinity e Antiaffinity s√£o conceitos que permitem que voc√™ defina regras para o agendamento de Pods em determinados Nodes. Com eles voc√™ pode definir regras para que Pods sejam agendados em Nodes espec√≠ficos, ou at√© mesmo para que Pods n√£o sejam agendados em Nodes espec√≠ficos.

Vamos entender como isso funciona na pr√°tica.

Voc√™ se lembra que adicionamos a label `gpu=true` nos Nodes que possuem GPU? Ent√£o, vamos utilizar essa label para garantir que o nosso Pod seja agendado somente neles. Para isso, vamos utilizar o conceito de Affinity.

Vamos criar um Deployment com 5 r√©plicas do `Nginx` com a seguinte configura√ß√£o:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx
  name: nginx
spec:
  replicas: 5
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx
        name: nginx
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: gpu
                operator: In
                values:
                - "true"
```
Vamos entender o que temos de novo:
```yaml
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: gpu
                operator: In
                values:
                - "true"
```
Onde:

- `affinity `√© o in√≠cio da configura√ß√£o de Affinity.
- `nodeAffinity` √© o conceito de Affinity para Nodes.
`requiredDuringSchedulingIgnoredDuringExecution` √© usado para indicar que o Pod s√≥ pode ser agendado em um Node que atenda aos requisitos de Affinity, est√° falando que essa regra √© obrigat√≥ria no momento do agendamento do Pod, mas que pode ser ignorada durante a execu√ß√£o do Pod.
- `nodeSelectorTerms` √© usado para indicar os termos de sele√ß√£o de Nodes, que ser√° usado para selecionar os Nodes que atendem aos requisitos de Affinity.
matchExpressions √© usado para indicar as express√µes de sele√ß√£o de Nodes, ou seja, o nome da label, o operador e o valor da label.
- `key` √© o nome da label que queremos utilizar para selecionar os Nodes.
- `operator` √© o operador que queremos utilizar. Nesse caso, estamos utilizando o operador In, que significa que o valor da label precisa estar dentro dos valores que estamos informando.
- `values` √© o valor da label que queremos utilizar para selecionar os Nodes.
Sendo assim, estamos falando para o Kubernetes que o nosso Pod s√≥ pode ser agendado em um Node que tenha a label `gpu=true`. Simples assim!

Vamos aplicar esse Deployment e ver o que acontece.
```sh
kubectl apply -f gpu-deployment.yaml
```
Se verificarmos os Pods agora, veremos que os nossos Pods est√£o rodando somente nos Nodes que possuem a label `gpu=true`.
```sh
kubectl get pods -o wide
```
A sa√≠da mostrar√° algo como:
```sh
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE              NOMINATED NODE   READINESS GATES
nginx-5dd89c4b9b-hwzcx   1/1     Running   0          4s    10.244.3.13   guilda-worker1    <none>           <none>
nginx-5dd89c4b9b-m4fj2   1/1     Running   0          4s    10.244.5.37   guilda-worker4   <none>           <none>
nginx-5dd89c4b9b-msnv8   1/1     Running   0          4s    10.244.3.14   guilda-worker1    <none>           <none>
nginx-5dd89c4b9b-nlcgs   1/1     Running   0          4s    10.244.5.36   guilda-worker4   <none>           <none>
nginx-5dd89c4b9b-trgw7   1/1     Running   0          4s    10.244.3.12   guilda-worker1    <none>           <none>
```
Isso demonstra o poder do `Affinity`. Podemos controlar com precis√£o onde nossos Pods ser√£o agendados, garantindo que workloads cr√≠ticos tenham os recursos que necessitam. Sensacional demais!

Agora vamos entender o conceito de `Antiaffinity`.

O `Antiaffinity`?
O `Antiaffinity` √© o conceito contr√°rio ao Affinity. Com ele voc√™ pode definir regras para que Pods n√£o sejam agendados em Nodes espec√≠ficos.

Vamos conhecer ele na pr√°tica!

Vamos relembrar como os nossos Nodes est√£o distribuidos.

- guilda-br-sp

  - guilda-br-sp-1
    - guilda-control-plane1
    - guilda-worker3
  - guilda-br-sp-2
    - guilda-control-plane4
    - guilda-worker1
- guilda-br-ssa
  - guilda-br-ssa-1
    - guilda-control-plane2
    - guilda-worker2
  - guilda-br-ssa-2
    - guilda-control-plane3
    - guilda-worker4
    - 
Ou seja, duas regi√µes e duas zonas de disponibilidade em cada regi√£o, certo?

Cada Node est√° com as labels region e datacenter devidamente configuradas, representando a regi√£o e a zona de disponibilidade que ele est√°.

Agora vamos imaginar que precisamos garantir que a nossa estar√° sendo distribuida entre as regi√µes e zonas de disponibilidade, ou seja, precisamos garantir que os nossos Pods n√£o sejam agendados em Nodes que estejam na mesma regi√£o e na mesma zona de disponibilidade.

Para isso, vamos utilizar o conceito de Antiaffinity. \o/

Vamos criar um Deployment com 5 r√©plicas do Nginx com a seguinte configura√ß√£o:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx
  name: nginx
spec:
  replicas: 5
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx
        name: nginx
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - nginx
            topologyKey: "datacenter"
```
Vamos entender o que estamos fazendo:

```yaml
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - nginx
            topologyKey: "datacenter"
```
Onde:

- `affinity` √© o in√≠cio da configura√ß√£o de Affinity.
- `podAntiAffinity` √© o conceito de Antiaffinity para Pods.
- `requiredDuringSchedulingIgnoredDuringExecution` √© usado para indicar que o Pod s√≥ pode ser agendado em um Node que atenda aos requisitos de Antiaffinity, est√° falando que essa regra √© obrigat√≥ria no momento do agendamento do Pod, mas que pode ser ignorada durante a execu√ß√£o do Pod.
- `labelSelector` √© usado para indicar os termos de sele√ß√£o de Pods, que ser√° usado para selecionar os Pods que atendem aos requisitos de Antiaffinity.
- `matchExpressions` √© usado para indicar as express√µes de sele√ß√£o de Pods, ou seja, o nome da label, o operador e o valor da label.
- `key` √© o nome da label que queremos utilizar para selecionar os Pods.
- `operator` √© o operador que queremos utilizar. Nesse caso, estamos utilizando o operador In, que significa que o valor da label precisa estar dentro dos valores que estamos informando.
- `values` √© o valor da label que queremos utilizar para selecionar os Pods.
- `topologyKey` √© usado para indicar a chave de topologia que ser√° usada para selecionar os Pods. Nesse caso, estamos utilizando a chave datacenter, que √© a chave que representa a zona de disponibilidade.

Sendo assim, estamos falando para o Kubernetes que o nosso Pod s√≥ pode ser agendado em um Node que n√£o tenha nenhum Pod com a label app=nginx na mesma zona de disponibilidade.

Voc√™ j√° deve estar imaginando que isso ir√° dar errado, certo? Pois somente temos 4 datacenters, e estamos tentando agendar 5 Pods, ou seja, um Pod n√£o ser√° agendado.

Vamos aplicar esse Deployment e ver o que acontece.
```sh
kubectl apply -f nginx-deployment.yaml
```
Se verificarmos os Pods agora, veremos que somente 4 Pods est√£o rodando, e um Pod n√£o foi agendado.
```sh
kubectl get pods -o wide
```
A sa√≠da mostrar√° algo como:
```sh
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE              NOMINATED NODE   READINESS GATES
nginx-58b9c8f764-7rqr7   1/1     Running   0          8s    10.244.4.32   guilda-worker3   <none>           <none>
nginx-58b9c8f764-mfpp7   1/1     Running   0          8s    10.244.6.33   guilda-worker2   <none>           <none>
nginx-58b9c8f764-n45p6   1/1     Running   0          8s    10.244.3.15   guilda-worker    <none>           <none>
nginx-58b9c8f764-qwjdk   0/1     Pending   0          8s    <none>        <none>            <none>           <none>
nginx-58b9c8f764-qzffs   1/1     Running   0          8s    10.244.5.38   guilda-worker4   <none>           <none>
```
Perceba que o Pod` nginx-58b9c8f764-qwjdk` est√° com o status `Pending`, pois n√£o foi poss√≠vel agendar ele em nenhum Node, pois em nossa regra n√≥s falamos que ele n√£o pode ser agendado em Nodes que tenham Pods com a label `app=nginx` na mesma zona de disponibilidade, ou seja, n√£o teremos nenhum Node que atenda a essa regra.

Sensacional demais, eu sei! \o/

## O que vimos e aprendemos ?
No conte√∫do de hoje, focamos em conceitos avan√ßados de Kubernetes, explorando Taints, Tolerations, Affinity, e Antiaffinity. Esses s√£o elementos cruciais para o gerenciamento eficiente de um cluster Kubernetes, permitindo controle refinado sobre onde e como os Pods s√£o agendados.

Taints e Tolerations:

- `Taints`: Utilizados para "manchar" Nodes, prevenindo que certos Pods sejam agendados neles, exceto se tiverem Tolerations correspondentes.
- `Tolerations`: Permitem que Pods sejam agendados em Nodes com Taints espec√≠ficos.
Affinity e Antiaffinity:

- `Affinity`: Permite especificar que Pods sejam agendados em Nodes espec√≠ficos, baseados em labels.
- `Antiaffinity`: Utilizado para evitar que Pods sejam agendados em Nodes espec√≠ficos, ajudando na distribui√ß√£o equilibrada de Pods em diferentes Nodes.
Vimos como organizar e gerenciar um cluster Kubernetes considerando diferentes cen√°rios, como manuten√ß√£o de Nodes, uso de recursos especiais (GPUs), e a distribui√ß√£o de Pods em diferentes regi√µes e datacenters para alta disponibilidade.

Abordamos tamb√©m como os Taints e Tolerations podem ser usados na pr√°tica, com comandos espec√≠ficos para adicionar e remover Taints, e como aplicar Tolerations em Pods. Isso incluiu a configura√ß√£o de Taints com diferentes efeitos como `NoSchedule`, `PreferNoSchedule`, e `NoExecute`.

No contexto de Affinity e Antiaffinity, detalhamos como esses conceitos s√£o aplicados para assegurar que Pods sejam alocados em Nodes espec√≠ficos ou distribu√≠dos entre Nodes para evitar pontos √∫nicos de falha, demonstrando a import√¢ncia desses conceitos para a confiabilidade e efici√™ncia de um cluster Kubernetes.